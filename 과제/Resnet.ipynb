{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c6ae2f29",
      "metadata": {
        "id": "c6ae2f29"
      },
      "source": [
        "# ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8cb4e241",
      "metadata": {
        "id": "8cb4e241"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "05dc005b",
      "metadata": {
        "id": "05dc005b"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion_factor = 1\n",
        "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1):\n",
        "        # 여기에 코드를 작성해주세요\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1= nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1= nn.BatchNorm2d(out_channels)\n",
        "        self.conv2= nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2= nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        #Shortcut (stride가 1이 아니거나 채널 다를 때 맞춰줌)\n",
        "        self.shortcut= nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut= nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        residual=x # 잔차\n",
        "        x= F.relu(self.bn1(self.conv1(x)))\n",
        "        x= self.bn2(self.conv2(x))\n",
        "        x += self.shortcut(residual) # 지름길 더하기\n",
        "        x= F.relu(x)\n",
        "\n",
        "        # 여기에 코드를 작성해주세요\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6abd7465",
      "metadata": {
        "id": "6abd7465"
      },
      "outputs": [],
      "source": [
        "class BottleNeck(nn.Module):\n",
        "    expansion_factor = 4 # 숫자를 작성해주세요\n",
        "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1):\n",
        "        # 여기에 코드를 작성해주세요\n",
        "        super(BottleNeck, self).__init__()\n",
        "        mid_channels= out_channels\n",
        "        self.conv1= nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn1= nn.BatchNorm2d(mid_channels)\n",
        "        self.conv2= nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2= nn.BatchNorm2d(mid_channels)\n",
        "        self.conv3= nn.Conv2d(mid_channels, out_channels*self.expansion_factor, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn3= nn.BatchNorm2d(out_channels*self.expansion_factor)\n",
        "\n",
        "        self.shortcut= nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels*self.expansion_factor:\n",
        "            self.shortcut= nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels*self.expansion_factor, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels*self.expansion_factor)\n",
        "            )\n",
        "\n",
        "    def forward(self, x:Tensor) -> Tensor:\n",
        "        residual= x\n",
        "        x= F.relu(self.bn1(self.conv1(x)))\n",
        "        x= F.relu(self.bn2(self.conv2(x)))\n",
        "        x= self.bn3(self.conv3(x))\n",
        "        x += self.shortcut(residual)\n",
        "        x= F.relu(x)\n",
        "        # 여기에 코드를 작성해주세요\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "674ce3ba",
      "metadata": {
        "id": "674ce3ba"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        # 여기에 코드를 작성해주세요\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels=64\n",
        "\n",
        "        #초기 layer\n",
        "        self.conv1= nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1= nn.BatchNorm2d(64)\n",
        "        self.maxpool= nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        #ResNet의 4개 stage\n",
        "        self.layer1= self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2= self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3= self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4= self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "\n",
        "        self.avgpool= nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc= nn.Linear(512*block.expansion_factor, num_classes)\n",
        "        self._init_layer()\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion_factor\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _init_layer(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x= F.relu(self.bn1(self.conv1(x)))\n",
        "        x= self.maxpool(x)\n",
        "\n",
        "        x= self.layer1(x)\n",
        "        x= self.layer2(x)\n",
        "        x= self.layer3(x)\n",
        "        x= self.layer4(x)\n",
        "        x= self.avgpool(x)\n",
        "        x= torch.flatten(x, 1)\n",
        "        x= self.fc(x)\n",
        "\n",
        "        # 여기에 코드를 작성해주세요\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4cc02570",
      "metadata": {
        "id": "4cc02570"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "    def resnet18(self):\n",
        "        res18= ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "        return res18\n",
        "        # 여기에 코드를 작성해주세요\n",
        "\n",
        "    def resnet34(self):\n",
        "        res34= ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "        return res34\n",
        "        # 여기에 코드를 작성해주세요\n",
        "\n",
        "    def resnet50(self):\n",
        "        res50= ResNet(BottleNeck, [3, 4, 6, 3])\n",
        "\n",
        "        return res50\n",
        "        # 여기에 코드를 작성해주세요\n",
        "\n",
        "    def resnet101(self):\n",
        "        res101= ResNet(BottleNeck, [3, 4, 23, 3])\n",
        "\n",
        "        return res101\n",
        "        # 여기에 코드를 작성해주세요\n",
        "\n",
        "    def resnet152(self):\n",
        "        res152= ResNet(BottleNeck, [3, 8, 36, 3])\n",
        "        return res152\n",
        "        # 여기에 코드를 작성해주세요\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a305a18b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a305a18b",
        "outputId": "60718949-2ebd-4dc6-90b0-683bd1699961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "model = Model().resnet152()\n",
        "y = model(torch.randn(1, 3, 224, 224))\n",
        "print(y.size())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# hyper-parameters\n",
        "learning_rate = 0.01\n",
        "weight_decay = 1e-4\n",
        "momentum = 0.9\n",
        "batch_size = 128\n",
        "num_epochs = 1"
      ],
      "metadata": {
        "id": "ExS5XZRgGbFJ"
      },
      "id": "ExS5XZRgGbFJ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_transform(train_mean, train_std, test_mean, test_std):\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(train_mean, train_std),\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(224),\n",
        "        transforms.Normalize(test_mean, test_std),\n",
        "    ])\n",
        "\n",
        "    return train_transform, test_transform\n",
        "\n",
        "def do_mean_std(train_data, test_data):\n",
        "    train_mean_rgb = [np.mean(x.numpy(), axis=(1,2)) for x, _ in train_data]\n",
        "    train_std_rgb  = [np.std(x.numpy(), axis=(1,2)) for x, _ in train_data]\n",
        "\n",
        "    test_mean_rgb = [np.mean(x.numpy(), axis=(1,2)) for x, _ in test_data]\n",
        "    test_std_rgb  = [np.std(x.numpy(), axis=(1,2)) for x, _ in test_data]\n",
        "\n",
        "    train_mean = np.mean(train_mean_rgb, axis=0).tolist()\n",
        "    train_std  = np.mean(train_std_rgb, axis=0).tolist()\n",
        "    test_mean  = np.mean(test_mean_rgb, axis=0).tolist()\n",
        "    test_std   = np.mean(test_std_rgb, axis=0).tolist()\n",
        "\n",
        "    return train_mean, train_std, test_mean, test_std\n"
      ],
      "metadata": {
        "id": "MczBOjbbGo9G"
      },
      "id": "MczBOjbbGo9G",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(train_data, test_data):\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    # 여기에 코드를 작성해주세요\n",
        "    test_loader  = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "    # 여기에 코드를 작성해주세요\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "fVkF5w-SGrf2"
      },
      "id": "fVkF5w-SGrf2",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.STL10(\n",
        "    root='./data',\n",
        "    split='train',\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.STL10(\n",
        "    root='./data',\n",
        "    split='test',\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-7rxnxwGsjU",
        "outputId": "9e69e5e3-a421-449e-ed2b-766ada6a8247"
      },
      "id": "o-7rxnxwGsjU",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.64G/2.64G [02:46<00:00, 15.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mean, train_std, test_mean, test_std = do_mean_std(train_data, test_data)\n",
        "train_transform, test_transform = do_transform(train_mean, train_std, test_mean, test_std)\n",
        "\n",
        "train_data.transform = train_transform\n",
        "test_data.transform  = test_transform\n",
        "\n",
        "train_loader, test_loader = get_dataloader(train_data, test_data)"
      ],
      "metadata": {
        "id": "LEmzcJI2GtyS"
      },
      "id": "LEmzcJI2GtyS",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3xDfRb-Gv5M",
        "outputId": "9eaf25fb-589d-40a1-dfb7-96b7808f4fb4"
      },
      "id": "I3xDfRb-Gv5M",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "model = Model().resnet152().to(device)\n",
        "# 여기에 코드를 작성해주세요\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# 여기에 코드를 작성해주세요\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "# 여기에 코드를 작성해주세요\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
        "# 여기에 코드를 작성해주세요\n"
      ],
      "metadata": {
        "id": "U0U94osIGxKd"
      },
      "id": "U0U94osIGxKd",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    # -------- Train --------\n",
        "    model.train()\n",
        "    correct, count = 0, 0\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for step, (images, labels) in enumerate(train_loader, start=1):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss= criterion(model(images), labels)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        count += len(labels)\n",
        "        correct += (model(images).argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "        # 여기에 코드를 작성해주세요\n",
        "\n",
        "        print(\n",
        "            f\"[Train] Epoch {epoch} \"\n",
        "            f\"Step {step}/{len(train_loader)} \"\n",
        "            f\"Acc {(correct/count)*100:.2f}% \"\n",
        "            f\"Loss {(train_loss/count):.4f}\"\n",
        "        )\n",
        "\n",
        "    # -------- Validation --------\n",
        "    model.eval()\n",
        "    correct, count = 0, 0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step, (images, labels) in enumerate(test_loader, start=1):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            # 여기에 코드를 작성해주세요\n",
        "\n",
        "            outputs=model(images)\n",
        "\n",
        "            loss= criterion(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            count+= labels.size(0)\n",
        "            correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "\n",
        "            print(\n",
        "                f\"[Valid] Step {step}/{len(test_loader)} \"\n",
        "                f\"Acc {(correct/count)*100:.2f}% \"\n",
        "                f\"Loss {(valid_loss/count):.4f}\"\n",
        "            )\n",
        "\n",
        "    scheduler.step(valid_loss)"
      ],
      "metadata": {
        "id": "B-MYOufzGyMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c6fb87f-271b-45f5-85db-752b2485d47f"
      },
      "id": "B-MYOufzGyMx",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train] Epoch 0 Step 1/40 Acc 20.31% Loss 0.0188\n",
            "[Train] Epoch 0 Step 2/40 Acc 18.75% Loss 0.0098\n",
            "[Train] Epoch 0 Step 3/40 Acc 17.19% Loss 0.0062\n",
            "[Train] Epoch 0 Step 4/40 Acc 16.21% Loss 0.0047\n",
            "[Train] Epoch 0 Step 5/40 Acc 15.94% Loss 0.0038\n",
            "[Train] Epoch 0 Step 6/40 Acc 15.23% Loss 0.0029\n",
            "[Train] Epoch 0 Step 7/40 Acc 14.96% Loss 0.0027\n",
            "[Train] Epoch 0 Step 8/40 Acc 14.65% Loss 0.0022\n",
            "[Train] Epoch 0 Step 9/40 Acc 14.06% Loss 0.0020\n",
            "[Train] Epoch 0 Step 10/40 Acc 13.91% Loss 0.0019\n",
            "[Train] Epoch 0 Step 11/40 Acc 14.28% Loss 0.0016\n",
            "[Train] Epoch 0 Step 12/40 Acc 13.93% Loss 0.0018\n",
            "[Train] Epoch 0 Step 13/40 Acc 13.88% Loss 0.0016\n",
            "[Train] Epoch 0 Step 14/40 Acc 13.95% Loss 0.0015\n",
            "[Train] Epoch 0 Step 15/40 Acc 14.17% Loss 0.0011\n",
            "[Train] Epoch 0 Step 16/40 Acc 14.16% Loss 0.0013\n",
            "[Train] Epoch 0 Step 17/40 Acc 14.34% Loss 0.0010\n",
            "[Train] Epoch 0 Step 18/40 Acc 14.41% Loss 0.0010\n",
            "[Train] Epoch 0 Step 19/40 Acc 14.47% Loss 0.0009\n",
            "[Train] Epoch 0 Step 20/40 Acc 14.57% Loss 0.0009\n",
            "[Train] Epoch 0 Step 21/40 Acc 14.62% Loss 0.0009\n",
            "[Train] Epoch 0 Step 22/40 Acc 14.74% Loss 0.0008\n",
            "[Train] Epoch 0 Step 23/40 Acc 14.74% Loss 0.0009\n",
            "[Train] Epoch 0 Step 24/40 Acc 14.78% Loss 0.0009\n",
            "[Train] Epoch 0 Step 25/40 Acc 14.84% Loss 0.0007\n",
            "[Train] Epoch 0 Step 26/40 Acc 14.87% Loss 0.0008\n",
            "[Train] Epoch 0 Step 27/40 Acc 14.90% Loss 0.0006\n",
            "[Train] Epoch 0 Step 28/40 Acc 15.12% Loss 0.0007\n",
            "[Train] Epoch 0 Step 29/40 Acc 14.90% Loss 0.0007\n",
            "[Train] Epoch 0 Step 30/40 Acc 15.05% Loss 0.0006\n",
            "[Train] Epoch 0 Step 31/40 Acc 15.15% Loss 0.0006\n",
            "[Train] Epoch 0 Step 32/40 Acc 15.21% Loss 0.0006\n",
            "[Train] Epoch 0 Step 33/40 Acc 15.29% Loss 0.0005\n",
            "[Train] Epoch 0 Step 34/40 Acc 15.23% Loss 0.0006\n",
            "[Train] Epoch 0 Step 35/40 Acc 15.25% Loss 0.0005\n",
            "[Train] Epoch 0 Step 36/40 Acc 15.30% Loss 0.0005\n",
            "[Train] Epoch 0 Step 37/40 Acc 15.29% Loss 0.0005\n",
            "[Train] Epoch 0 Step 38/40 Acc 15.21% Loss 0.0005\n",
            "[Train] Epoch 0 Step 39/40 Acc 15.34% Loss 0.0005\n",
            "[Train] Epoch 0 Step 40/40 Acc 15.40% Loss 0.0004\n",
            "[Valid] Step 1/63 Acc 8.59% Loss 0.0504\n",
            "[Valid] Step 2/63 Acc 7.81% Loss 0.0390\n",
            "[Valid] Step 3/63 Acc 8.59% Loss 0.2890\n",
            "[Valid] Step 4/63 Acc 8.59% Loss 0.2979\n",
            "[Valid] Step 5/63 Acc 8.91% Loss 0.2430\n",
            "[Valid] Step 6/63 Acc 8.85% Loss 0.2055\n",
            "[Valid] Step 7/63 Acc 9.04% Loss 0.2134\n",
            "[Valid] Step 8/63 Acc 9.57% Loss 0.1978\n",
            "[Valid] Step 9/63 Acc 9.38% Loss 0.2736\n",
            "[Valid] Step 10/63 Acc 9.30% Loss 0.2481\n",
            "[Valid] Step 11/63 Acc 9.38% Loss 0.2288\n",
            "[Valid] Step 12/63 Acc 9.44% Loss 0.2468\n",
            "[Valid] Step 13/63 Acc 9.13% Loss 0.2576\n",
            "[Valid] Step 14/63 Acc 9.60% Loss 0.2647\n",
            "[Valid] Step 15/63 Acc 9.38% Loss 0.2744\n",
            "[Valid] Step 16/63 Acc 9.23% Loss 0.2760\n",
            "[Valid] Step 17/63 Acc 9.05% Loss 0.2608\n",
            "[Valid] Step 18/63 Acc 9.11% Loss 0.2490\n",
            "[Valid] Step 19/63 Acc 9.21% Loss 0.2443\n",
            "[Valid] Step 20/63 Acc 9.22% Loss 0.2558\n",
            "[Valid] Step 21/63 Acc 9.11% Loss 0.2458\n",
            "[Valid] Step 22/63 Acc 9.13% Loss 0.2396\n",
            "[Valid] Step 23/63 Acc 9.04% Loss 0.2328\n",
            "[Valid] Step 24/63 Acc 9.08% Loss 0.2458\n",
            "[Valid] Step 25/63 Acc 9.16% Loss 0.2415\n",
            "[Valid] Step 26/63 Acc 9.28% Loss 0.2396\n",
            "[Valid] Step 27/63 Acc 9.40% Loss 0.2346\n",
            "[Valid] Step 28/63 Acc 9.46% Loss 0.2275\n",
            "[Valid] Step 29/63 Acc 9.43% Loss 0.2203\n",
            "[Valid] Step 30/63 Acc 9.58% Loss 0.2151\n",
            "[Valid] Step 31/63 Acc 9.55% Loss 0.2112\n",
            "[Valid] Step 32/63 Acc 9.47% Loss 0.2125\n",
            "[Valid] Step 33/63 Acc 9.61% Loss 0.2066\n",
            "[Valid] Step 34/63 Acc 9.65% Loss 0.2010\n",
            "[Valid] Step 35/63 Acc 9.73% Loss 0.1972\n",
            "[Valid] Step 36/63 Acc 9.74% Loss 0.1922\n",
            "[Valid] Step 37/63 Acc 9.76% Loss 0.1887\n",
            "[Valid] Step 38/63 Acc 9.66% Loss 0.1852\n",
            "[Valid] Step 39/63 Acc 9.68% Loss 0.1831\n",
            "[Valid] Step 40/63 Acc 9.65% Loss 0.1927\n",
            "[Valid] Step 41/63 Acc 9.68% Loss 0.1906\n",
            "[Valid] Step 42/63 Acc 9.65% Loss 0.1879\n",
            "[Valid] Step 43/63 Acc 9.79% Loss 0.1915\n",
            "[Valid] Step 44/63 Acc 9.82% Loss 0.1884\n",
            "[Valid] Step 45/63 Acc 9.81% Loss 0.1846\n",
            "[Valid] Step 46/63 Acc 9.78% Loss 0.1819\n",
            "[Valid] Step 47/63 Acc 9.77% Loss 0.1789\n",
            "[Valid] Step 48/63 Acc 9.88% Loss 0.1792\n",
            "[Valid] Step 49/63 Acc 9.89% Loss 0.1803\n",
            "[Valid] Step 50/63 Acc 10.02% Loss 0.1775\n",
            "[Valid] Step 51/63 Acc 10.02% Loss 0.1855\n",
            "[Valid] Step 52/63 Acc 10.08% Loss 0.1829\n",
            "[Valid] Step 53/63 Acc 10.10% Loss 0.1875\n",
            "[Valid] Step 54/63 Acc 10.08% Loss 0.1934\n",
            "[Valid] Step 55/63 Acc 10.03% Loss 0.1902\n",
            "[Valid] Step 56/63 Acc 10.03% Loss 0.1999\n",
            "[Valid] Step 57/63 Acc 10.07% Loss 0.1986\n",
            "[Valid] Step 58/63 Acc 10.05% Loss 0.1994\n",
            "[Valid] Step 59/63 Acc 10.02% Loss 0.2001\n",
            "[Valid] Step 60/63 Acc 10.03% Loss 0.1977\n",
            "[Valid] Step 61/63 Acc 10.00% Loss 0.2012\n",
            "[Valid] Step 62/63 Acc 10.01% Loss 0.2003\n",
            "[Valid] Step 63/63 Acc 10.01% Loss 0.1993\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}